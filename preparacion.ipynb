{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import initializers\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "D1 (Dense)                   (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "A1 (Activation)              (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "D2 (Dense)                   (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "A2 (Activation)              (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "D3 (Dense)                   (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "A3 (Activation)              (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 26\n",
      "Trainable params: 26\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(input_dim=2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(3, name='D1', input_dim=input_dim, kernel_initializer=initializers.RandomNormal(stddev=0.5), \n",
    "                    bias_initializer=initializers.RandomNormal(stddev=0.5)))\n",
    "    model.add(Activation('sigmoid', name='A1'))\n",
    "    model.add(Dense(2, name='D2', kernel_initializer=initializers.RandomNormal(stddev=0.5), \n",
    "                    bias_initializer=initializers.RandomNormal(stddev=0.5)))\n",
    "    model.add(Activation('sigmoid', name='A2'))\n",
    "    model.add(Dense(3,  name='D3', kernel_initializer=initializers.RandomNormal(stddev=0.5), \n",
    "                    bias_initializer=initializers.RandomNormal(stddev=0.5)))\n",
    "    model.add(Activation('softmax', name='A3'))\n",
    "    model.compile(SGD(lr=0.1), loss='mse')\n",
    "    model.save('simple_model.hdf5')\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('simple_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.3315773 , -0.9603926 , -0.6638519 ],\n",
      "       [-0.89203614,  0.06406464, -0.70949006]], dtype=float32), array([ 0.21058255, -1.1298051 ,  0.24498418], dtype=float32), array([[ 0.9079479 ,  0.18939708],\n",
      "       [-0.887635  , -0.41770914],\n",
      "       [ 0.59481746,  0.71403545]], dtype=float32), array([-0.80065525,  0.51503426], dtype=float32), array([[-0.06259476, -0.641043  , -0.435419  ],\n",
      "       [ 0.63357514,  0.05387408,  0.02064688]], dtype=float32), array([-0.18157978,  0.18466745, -0.6780159 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "lr = 1\n",
    "model = load_model('simple_model.hdf5')\n",
    "#model = get_model()\n",
    "model.compile(SGD(lr=lr), loss='mse')\n",
    "\n",
    "# model.summary()\n",
    "weights = model.get_weights()\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_jac(Xin):\n",
    "    return sigmoid(Xin)*(1-sigmoid(Xin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19661193, 0.10499359])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_jac(np.array([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08192507, -0.02203304, -0.05989202],\n",
       "       [-0.02203304,  0.18483645, -0.1628034 ],\n",
       "       [-0.05989202, -0.1628034 ,  0.22269543]])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(z):\n",
    "    exps = np.exp(z)\n",
    "    sums = np.sum(exps)\n",
    "    return np.divide(exps, sums)\n",
    "\n",
    "\n",
    "def softmax_jac(Xin):\n",
    "    sm = softmax(Xin)\n",
    "    return np.diag(sm) - sm.reshape(-1, 1).dot(sm.reshape(1, -1))\n",
    "    \n",
    "softmax_jac(np.array([1, 2, 3]))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09003057, 0.24472847, 0.66524096])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = softmax(np.array([1, 2, 3]))\n",
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[3.4, 2.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26419955, 0.41198996, 0.32381058]], dtype=float32)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.81235484]]\n"
     ]
    }
   ],
   "source": [
    "D1_out = X.dot(weights[0]) + weights[1]\n",
    "A1_out = sigmoid(D1_out)\n",
    "D2_out = A1_out.dot(weights[2]) + weights[3]\n",
    "A2_out = sigmoid(D2_out)\n",
    "y_ = A2_out.dot(weights[4]) + weights[5] # D3_out\n",
    "print(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si el y es igual a la salida entonces los pesos no se modifican\n",
    "y = np.array([[0.93]])\n",
    "#y = np.array([[out]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.03580038]]\n"
     ]
    }
   ],
   "source": [
    "loss = (y-y_)**2\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0358004570007324"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 705us/step - loss: 3.0358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x63ba90610>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para D1\n",
    "$\\theta_t = \\theta_{t-1} - \\mathrm{learning\\_rate} * g_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15024746, -0.0927999 ],\n",
       "       [ 0.07026835,  0.04340104]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sigmoid_dif(D1_out).T*weights[2].dot(sigmoid_dif(D2_out).T*weights[4]*(-2*(y-y_)))).dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15024746, -0.0927999 ],\n",
       "       [ 0.07026835,  0.04340104]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X*(sigmoid_dif(D1_out).T*weights[2].dot(sigmoid_dif(D2_out).T*weights[4]*(-2*(y-y_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivada del MSE evaluada en y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.48470968]]\n"
     ]
    }
   ],
   "source": [
    "# Derivada de la loss respecto a y_\n",
    "mse_der = -2*(y-y_)\n",
    "print(mse_der)\n",
    "prop_grad_y_ = mse_der"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta para D3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.26015587 -0.94712252 -1.49670461]] [[-3.48470968]]\n"
     ]
    }
   ],
   "source": [
    "# Gradiente de y_ respecto a cada parámetro\n",
    "# Recordar que cuando derivo una capa dense respecto a cada parámetro, me da la entrada a esa cada. El Bias es como si entrarada con 1\n",
    "\n",
    "y__grad_ws_d3 = A2_out\n",
    "y__grad_bias_d3 = 1\n",
    "\n",
    "delta_ws_d3 = y__grad_ws_d3*prop_grad_y_*lr\n",
    "delta_bias_d3 = y__grad_bias_d3*prop_grad_y_*lr\n",
    "print(delta_ws_d3, delta_bias_d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.67218125e-08, 5.60790036e-08, 1.47877194e-07]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pesos utlima capa modificados\n",
    "new_weights[4].T - (weights[4].T - delta_ws_d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.2371895e-08]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bias ultima capa modificado\n",
    "new_weights[5].T - (weights[5].T - delta_bias_d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_dif(X):\n",
    "    return sigmoid(X)*(1-sigmoid(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.84538307]\n",
      " [1.28369178]\n",
      " [1.53521471]]\n",
      "[[0.19267999]\n",
      " [0.25407076]\n",
      " [0.37617463]]\n"
     ]
    }
   ],
   "source": [
    "# Con que entro a A2? D2_out\n",
    "# Necesito y__grad_in_d3 (Gradiente de y_ respecto a la entrada al bloque d3)\n",
    "y__grad_in_d3 = weights[4]\n",
    "prop_grad_d3 = y__grad_in_d3*prop_grad_y_\n",
    "print(prop_grad_d3) # Entrada de D3\n",
    "prop_grad_A2 = sigmoid_dif(D2_out).T*prop_grad_d3*lr\n",
    "print(prop_grad_A2) # Entrada de A2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_ws_d2 = (prop_grad_A2*A1_out).T\n",
    "delta_bias_d2 = prop_grad_A2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.25856622e-09 -5.46572199e-09  1.02110236e-08]\n",
      " [-1.62406742e-08 -1.44461989e-08 -1.64342799e-08]]\n",
      "[[-1.48808340e-08  1.29551381e-09  1.10791643e-09]]\n"
     ]
    }
   ],
   "source": [
    "print(new_weights[2] - (weights[2] - delta_ws_d2))\n",
    "print(new_weights[3] - (weights[3] - delta_bias_d2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.19309713]\n",
      " [ 0.082746  ]]\n",
      "[[-0.04419043]\n",
      " [ 0.02066716]]\n"
     ]
    }
   ],
   "source": [
    "d2_out_grad_in_d2 = weights[2]\n",
    "prop_grad_d2 = d2_out_grad_in_d2.dot(prop_grad_A2)\n",
    "print(prop_grad_d2) \n",
    "prop_grad_A1 = sigmoid_dif(D1_out).T*prop_grad_d2*lr\n",
    "print(prop_grad_A1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04419043],\n",
       "       [ 0.02066716]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_grad_A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.15024746  0.07026835]\n",
      " [-0.0927999   0.04340104]]\n"
     ]
    }
   ],
   "source": [
    "delta_ws_d1 = (X*prop_grad_A1).T\n",
    "delta_bias_d1 = prop_grad_A1.T\n",
    "print(delta_ws_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.94892052e-08 -8.69921603e-09]\n",
      " [-1.77648721e-08 -9.97487437e-09]]\n",
      "[[-2.40702032e-08 -4.74994019e-09]]\n"
     ]
    }
   ],
   "source": [
    "print(new_weights[0] - (weights[0] - delta_ws_d1))\n",
    "print(new_weights[1] - (weights[1] - delta_bias_d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "A3_model = Model(model.input, model.get_layer('A3').input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x642dd54d0>"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A3_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model = load_model('simple_model.hdf5')\n",
    "inputs = tf.constant(X)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    preds = model(inputs)\n",
    "    loss = model.loss(tf.constant(y), preds)\n",
    "\n",
    "grads = tape.gradient(loss, A3_model(inputs))\n",
    "print(grads)\n",
    "# grads = tape.gradient(loss, model.get_layer(\"D3\").trainable_variables)\n",
    "# print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.losses.mean_squared_error(y_true, y_pred)>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "D1 (Dense)                   (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "A1 (Activation)              (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "D2 (Dense)                   (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "A2 (Activation)              (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "D3 (Dense)                   (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "A3 (Activation)              (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 26\n",
      "Trainable params: 26\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_63_4/kernel:0' shape=(2, 2) dtype=float32, numpy=\n",
       " array([[-0.0132913 ,  0.39277452],\n",
       "        [ 0.61490476, -0.11834475]], dtype=float32)>,\n",
       " <tf.Variable 'dense_63_4/bias:0' shape=(2,) dtype=float32, numpy=array([ 0.9016673 , -0.33314416], dtype=float32)>,\n",
       " <tf.Variable 'dense_64_4/kernel:0' shape=(2, 3) dtype=float32, numpy=\n",
       " array([[-0.4778273 ,  0.3336253 , -0.03871878],\n",
       "        [ 0.07612087,  0.27854922, -0.02718207]], dtype=float32)>,\n",
       " <tf.Variable 'dense_64_4/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.36176467, -0.86578524, -0.10165475], dtype=float32)>,\n",
       " <tf.Variable 'dense_65_4/kernel:0' shape=(3, 1) dtype=float32, numpy=\n",
       " array([[0.47252566],\n",
       "        [0.73365825],\n",
       "        [0.7718087 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_65_4/bias:0' shape=(1,) dtype=float32, numpy=array([1.4085784], dtype=float32)>]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_65_4/Identity:0' shape=(None, 1) dtype=float32>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-e6201d067514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   3847\u001b[0m   \"\"\"\n\u001b[1;32m   3848\u001b[0m   return gradients_module.gradients(\n\u001b[0;32m-> 3849\u001b[0;31m       loss, variables, colocate_gradients_with_ops=True)\n\u001b[0m\u001b[1;32m   3850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    173\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    489\u001b[0m   \u001b[0;34m\"\"\"Implementation of gradients().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     raise RuntimeError(\"tf.gradients is not supported when eager execution \"\n\u001b[0m\u001b[1;32m    492\u001b[0m                        \"is enabled. Use tf.GradientTape instead.\")\n\u001b[1;32m    493\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msrc_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
     ]
    }
   ],
   "source": [
    "K.gradients(model.output, model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.GradientTape()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
